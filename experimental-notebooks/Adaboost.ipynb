{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(872136, 34)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read processe file\n",
    "df = pd.read_csv('../data/processed_balanced_transaction.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets separate Level and features, Scaled feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(['isFraud'],axis=1), df['isFraud']\n",
    "# scale the features by standard scaler\n",
    "standard_scaler = StandardScaler()\n",
    "X = standard_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into train test \n",
    " We are spliting data into train and test with ratio 30%. Means 30% test and 70% train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an AdaBoost Classifier and fit the model and report accuracy\n",
    "\n",
    "Let's create the AdaBoost Model using Scikit-learn. AdaBoost uses Decision Tree Classifier as default Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud      0.696     0.673     0.684    130734\n",
      "       Fraud      0.684     0.707     0.695    130907\n",
      "\n",
      "    accuracy                          0.690    261641\n",
      "   macro avg      0.690     0.690     0.690    261641\n",
      "weighted avg      0.690     0.690     0.690    261641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "target_names = ['Not Fraud', 'Fraud']\n",
    "abc = AdaBoostClassifier(n_estimators=50,\n",
    "                         learning_rate=1,\n",
    "                         random_state=0)\n",
    "abc.fit(X_train, y_train)\n",
    "y_pred = abc.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred, digits=3, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation\n",
    "we are going to apply k-fold cross-validation.\n",
    "\n",
    "it will split the original data set into k subsets and use one of the subsets as the testing set and the remaining as the training sets. This process iterated k times until every subset have been used as the testing set. Since 10-fold cross-validation is the most popular one, we are going to use that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(abc, X_train, y_train, cv=10)\n",
    "print('Average score: {}'.format(round(np.mean(cv_scores),3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(cv_scores)\n",
    "plt.title('Average score: {}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Tuning\n",
    "\n",
    "In classification technique, there are some parameters that can be tuned to optimize the classification. \n",
    "In AdaBoost Classifier we can tune \n",
    "\n",
    "- base_estimator\n",
    "- n_estimators\n",
    "- learning_rate\n",
    "\n",
    "Grid Search explores a range of parameters and finds the best combination of parameters. Then repeat the process several times until the best parameters are discovered. \n",
    "lets use grid search to get best params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#Creating a grid of hyperparameters\n",
    "grid_params = {    'n_estimators': [50,100]}\n",
    "#Use GridSearch\n",
    "abc_grid_search = GridSearchCV(AdaBoostClassifier(), grid_params, cv = 10, n_jobs = -1)\n",
    "\n",
    "#Fit the model\n",
    "abc_grid_search.fit(X_train, y_train)\n",
    "print('Best score: {}'.format(abc_grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(abc_grid_search.best_params_))\n",
    "\n",
    "best_abc_classifier = abc_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_abc_classifier.fit(X_train, y_train)\n",
    "y_pred_abc = best_abc_classifier.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred_abc, digits=3, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36workshop",
   "language": "python",
   "name": "p36workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
